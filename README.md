# Arm UNICEF Disaster Vulnerability Challenge Data

This repository contains the code and resources for the **Arm UNICEF Disaster Vulnerability Challenge**. The goal of this project is to detect and classify different types of dwellings in aerial imagery over Malawi using two object detection models: **Detectron2** and **YOLOv8**.

## Project Overview

The dataset consists of aerial images taken over parts of Malawi. These images capture traditional houses, typically made with mud walls and grass-thatched roofs. The task is to classify the dwelling units into three categories:
1. **Other**
2. **Tin**
3. **Thatch**

### Dataset Details
Link: `https://www.kaggle.com/datasets/rajsahu2004/arm-unicef-disaster-vulnerability-challenge-data`
- **Training images**: 4,772 images
- **Test images**: 2,045 images
- **Labels**: 
  - `1`: Other
  - `2`: Tin
  - `3`: Thatch
  
### Objective

To build an object detection model that can identify and classify these types of dwellings using aerial imagery.

## Models Used

### 1. Detectron2 on Custom Dataset - Object Detection

Detectron2 is a high-performance library for object detection and segmentation developed by Facebook AI Research. In this approach, we utilized a custom dataset based on the aerial imagery and trained a model to detect and classify the different types of dwellings.

- **Library**: Detectron2
- **Preprocessing**: Custom dataset preparation
- **Training**: Transfer learning on a pre-trained COCO model
- **Performance**: Includes metrics such as precision, recall, and mAP

Notebook: [`Detectron2 on Custom Dataset`]

### 2. YOLOv8 - Zindi

YOLOv8 is a state-of-the-art object detection model known for its speed and accuracy. In this approach, we used the YOLOv8 model to train on the same dataset, focusing on real-time detection capabilities.

- **Library**: YOLOv8 (Ultralytics)
- **Preprocessing**: YOLO format for data annotations
- **Training**: Fine-tuning a pre-trained YOLOv8 model on our dataset
- **Performance**: Focus on high-speed inference and accuracy

Notebook: [`YOLOv8 - Zindi`]

## Installation

To run the notebooks and replicate the results, follow these steps:

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/unicef-disaster-vulnerability.git
cd unicef-disaster-vulnerability
```

### 2. Set Up the Environment

- Create a virtual environment and activate it:

```bash
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
```

- Install the required packages:

```bash
pip install -r requirements.txt
```

### 3. Download the Dataset

Download the dataset from [Kaggle](https://www.kaggle.com/datasets/unicef-arm-disaster-vulnerability) and place it in the `data/` directory.

```bash
mkdir data
# move the dataset files into the data directory
```

### 4. Running the Notebooks

You can run the notebooks in your environment or set up a Jupyter server:

```bash
jupyter notebook
```

Open the notebooks:
- `Detectron2 on Custom Dataset`
- `YOLOv8 - Zindi`

Follow the steps in each notebook to preprocess the data, train the models, and evaluate the performance.

## Results

The performance of both models is summarized in the following table:
| Detectron2 : Training Loss evaluation

![image](https://github.com/user-attachments/assets/677f92df-3477-41c3-b690-62d4ba90e68b)

| Model          | MAE        | F1 Score- 0.7 threshold 
|----------------|------------|----------
| YOLOv8         | 0.9563     | 0.9567  


## Future Work

- Hyperparameter tuning for both models
- Exploring ensemble methods for improved accuracy
- Deploying the models for real-time inference

## Contributing

Contributions are welcome! Please fork this repository, create a feature branch, and submit a pull request with your changes.
